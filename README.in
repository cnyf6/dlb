------------------------------------------------------------
  Dynamic Load Balancing (DLB) Library
------------------------------------------------------------

========== Contact information =============================
Marta Garcia Gasulla
<marta.garcia@bsc.es>

Victor Lopez
<victor.lopez@bsc.es>

Web:
http://pm.bsc.es/dlb

Trac:
http://pm.bsc.es/projects/dlb

===========================================================

Version: @VERSION@
Support for: 
               * OpenMP + MPI 
               * OmpSs + MPI
               * SMPSs + MPI (not maintained)
               * OmpSs + Multiple Applications

------------------------------------------------------------
0 CONTENTS
------------------------------------------------------------

1 INTRODUCTION
2 INSTALLING THE LIBRARY
   2.1 REQUIREMENTS
   2.2 STEP BY STEP
3 RUNNING WITH DLB
   3.1 USING SUPPORT SCRIPTS PROVIDED
   3.2 BY HAND
      3.2.1 Tracing Application
      3.2.2 NANOS Application
      3.2.3 SMPSs Application
      3.2.4 OpenMP Application (not under NANOS environment)
4 DLB API

------------------------------------------------------------
1 INTRODUCTION
------------------------------------------------------------

DLB is a dynamic library designed to speed up hybrid applications with nested parallelism by improving the load balance inside each computational node.

In general DLB will redistribute the computational resources of the second level of parallelism to improve the load balance of the outer level of parallelism.

There are different load balancing algorithms implemented within DLB. They all relay on this main idea but they target different types of applications or situations.

The DLB library uses an interposition technique during runtime, therefor in most of the cases it is not necessary to analyze previously the application, modify it or recompile.

The current version of DLB supports the following programming models:

* MPI + OpenMP
* MPI + OmpSs
* MPI + SMPSs (not maintained)
* Multiple Applications + OmpSs

------------------------------------------------------------
2 COMPILING AND INSTALLING THE LIBRARY
------------------------------------------------------------
............................................................
   2.1 REQUIREMENTS
............................................................

- Any MPI library
- OpenMP or OmpSs compiler and runtime
- For tracing:
   * Extrae library 

............................................................
   2.2 STEP BY STEP
............................................................

   1 Make sure you meet the requirements
   
   2 Go to https://pm.bsc.es/projects/dlb/wiki/Downloads and grab the latest version of the library. Unpack the file and enter the directory. 

      $ tar xfj dlb-<<version>>.tar.bz2
      $ cd dlb-<<version>>

   3 Run configure. Check the configure flags to enable more or less features in the library. 

      $ ./configure --prefix=<<instalation-path>> <<configure-flags>>

         The most relevant flags in the configure:                                                                                                                                                                                            
            --prefix
            --with-mpi[=DIR]        specify where to find MPI libraries and includes [Optional]
            --with-cpus-per-node=N  Number of cpus per node [Optional]

   4 Build and install 

      $ make
         <<<compilation output>>>
      $ make install


------------------------------------------------------------
3 RUNNING WITH DLB 
------------------------------------------------------------
............................................................
   3.1 USING SUPPORT SCRIPTS PROVIDED
............................................................

The instalation of DLB includes a script to assist the user when using DLB.

The script will be installed under <dlb_instalation>/bin/run_with_dlb.sh

This script will set all the correct environment variables to run an application with or without DLB and at last execute it.

It is designed to be used with the tipical "mpirun" utility like follows:

   $> mpirun run_with_dlb.sh [OPTIONS] -- APP [APP_ARGS]

Except when we want to obtain the variables used and its values without running the application, we can use the --show flag and we do not need the mpirun:

   $> run_with_dlb.sh --show [OPTIONS] -- APP [APP_ARGS]

The available options are the following, this summary can be obtained also using run_with_dlb.sh --help.

OPTIONS:
--aggressive-init
--no-aggressive-init     : Enable/Disable creation of all threads at start time [Default = YES]
--debug                  : Use debug version of DLB [Default = NO]
--extrae-cfg x           : Use this extrae config file for tracing [Default EXTRAE_CONFIG_FILE env var = ]
--flavor x               : Application progamming model [Default = OMPSS]
      MPI_ONLY             : MPI only application
      OMPSS                : OMPSs application
      OMP                  : OMP application, not in Nanos runtime
      OMP-NANOS            : OMP application in Nanos runtime
      SMPSS                : SMPSs application
--keep                   : Keep generated script [Default = NO]
--mpi-wait-mode x        : MPI wwait mode when in a MPI blocking call [Default = BLOCK]
      BLOCK                : Blocking wait mode, not consuimg cpu
      1CPU                 : Polling wait mode, consuming cpu
--num-mpis-node x          : Number of MPI processes running in one node. Mandatory for OMP and SMPSS flavor 
--policy x               : DLB policy [Default = LeWI_mask]
      ORIG                 : Do not use DLB library
      NO                   : Do not load balance, use DLB just for profile
      LeWI                 : Lend When Idle policy
      LeWI_mask            : Lend When Idle and use cpu binding policy (Only available for OMPSs or OMP-NANOS flavor)
      RaL:                 : Redistribute and Lend policy with cpu binding (Only available for OMPSs or OMP-NANOS flavor)
--smpss-cfg x              : Path to SMPSs configuration file
--show                   : Do not run application but show output of this script [Default = NO]
--thread-distribution x  : Use an heterogeneous distribution of threads among MPI processes [Default = NO]
      NO                   : Use homogeneous thread distribution among MPI processes
      x-y-z-w              : Numbers separated by '-'. First MPI x threads, second MPI y threads...
--tracing                  : Trace application using Extrae [Default = NO]
-trace-lib                 : Trace application using this Extrae instalation [Default = /home/bsc15/bsc15994/MN3/extrae]


............................................................
   3.2 BY HAND 
............................................................

We can also run DLB setting the environment variables by hand. But we encourage to use the included script or at least use it with the --show option to get a list of the environment variables that the script would set and its values.

These are the environment variables that DLB might need and react to:

- LB_LEND_MODE: [ BLOCK | 1CPU ], default=BLOCK
      This variable will define the way DLB will lend the computational resources when in an MPI call. 
      BLOCK will lend all the computational resources assuming MPI uses a blocking mode and is not consuming cpus when in a blocking MPI call. 
      1CPU will keep one cpu when in a blocking MPI call, this option will asume MPI will be polling while waiting in a blocking MPI call.
      When setting this variable to BLOCK it is important to set the MPI runtime to use a blocking wait mode, this is usually done by setting an environment variable specific for each MPI implementation, we show here some variables for the MPI implementations we have tested:
         - MXMPI_RECV=blocking              #MPICH
         - OMPI_MCA_mpi_yield_when_idle=1   #OpenMPI
         - I_MPI_WAIT_MODE=1                #Intel MPI

- LB_POLICY: Load Balancing policy used within DLB for this execution, these are the available values:
         - NO                   : Do not load balance, use DLB just for profiling the application or debugging.
         - LeWI                 : Lend When Idle policy, an MPI process will lend its assigned threads when in a blocking MPI call.
         - LeWI_mask            : Lend When Idle and use cpu binding policy (Only available when using NANOS runtime with OMPSs or OpenMP model), an MPI process will lend its assigned cpus when in a blocking MPI call.
         - RaL:                 : Redistribute and Lend policy with cpu binding (Only available when using NANOS runtime with OMPSs or OpenMP model)"

- LB_AGGRESSIVE_INIT: [ YES | NO ], default=NO. 
      This variable will decide if all the available threads are created at the beggining of the execution or if they are created in the moment they are needed during the execution.

- LB_THREAD_DISTRIBUTION: [ NO | x-y-z-w ], default=NO.
      This variable offers the posibility of setting a heterogenaous distribution of threads among MPI processes. When NO is set an homogeneous distribution is used. When we set its value to numbers separated by dashes each number corresponds to the number of threads of an MPI process, in the example: x-y-z-w, MPI process 0 will run with x threads by default, MPI process 1 will run with y threads by default, MPI process 2 will run with z threads by default ad MPI process 3 will run with w threads by default.

Finally we will need to preload the correct library, this can be done  setting the LD_PRELOAD variable.

DLB libraries are usually found in a lib folder under the instalation of DLB.

libdlb.so            : Normal execution with DLB
libdlb_dummy.so      : To compile applications with DLB when we need to include some DLB API call
libdlb_dbg.so        : Run DLB in debug mode
libdlb_instr.so      : Execute with DLB and instrument with extrae. In this case we will need to add also to the LD_PRELOAD variable the corresponding lib***trace-lb.so
libdlb_instr_dbg.so  : Run with DLB in debug mode and instrument with extrae. In this case we will need to add also to the LD_PRELOAD variable the corresponding lib***trace-lb.so

............................................................
      3.2.1  Tracing Application
............................................................
If we are tracing the application with Extrae we will need to set the following variables:

EXTRAE_CONFIG_FILE pointing to a correct extrae xml file or EXTRAE_ON=1.

Remember to use the extrae library for the LD_PRELOAD with the "-lb" sufix.

............................................................
      3.2.2 NANOS Application
............................................................
When running a NANOS application we need to set the following information in the environment variable NX_ARGS.
When using DLB is mandatory to include the flag --enable-dlb.

If we are running with DLB and a balancing policy without binding we need to add this flag: --disable-binding (Balancing policies without binding: NO, LeWI)

If we are running with DLB and we want to obtain an extrae trace we need to add the flag: --instrumentation=extrae

............................................................
      3.2.3 SMPSs Application 
............................................................

- CSS_NUM_CPUS: Default number of smpss threads that will have each MPI process
- CSS_MAX_CPUS: Number of cores available per node. I.e the maximum number of threads that can run in one node.
- CSS_CONFIG_FILE: A smpss configuration file containing at least te following line: "dlb.enable=1"

............................................................
      3.2.4 OpenMP Application (not under NANOS environment)
............................................................

- OMP_NUM_THREADS: Number of cores available per node. I.e the maximum number of threads that can run in one node.


------------------------------------------------------------
4 DLB API 
------------------------------------------------------------

Additional to the interception technique and the automatic load balancing, DLB also offers an API for those cases where the developer know a specific issue of his application. 

To use the API the application must be compiled with the dummy version of the DLB library (libdlb_dummy.so). this library contains the symbols to the API but will not execute any DLB code unless we LD_PRELOAD the correct DLB library (libdlb.so).

The DLB API is the following:

- DLB_enable   : Enable DLB load balancing, it is enabled by default after the MPI_Init.
- DLB_disable  : Disable DLB load balancing temporarly, the following MPI calls will be ignored until we call DLB_enable.
- DLB_single   : Mark that we are entering a serial part of code, therefore we can lend all the threads except one.
- DLB_parallel : Mark that we are exiting a serial part of the code, at this point we will retrieve the threads that we have lended previously
- DLB_Lend     : Lend all the threads
- DLB_Retrieve : Retrieve all my threads
- DLB_Barrier  : Do an MPI barrier at node level, and lend all the threads (or keep one depending on the BLOCKING MODE).
